**1. Probabilities and Statistics refresher**

&#10230; Relembrando Probabilidades e Estatística

<br>

**2. Introduction to Probability and Combinatorics**

&#10230; Introdução a Probabilidade e Combinatória

<br>

**3. Sample space ― The set of all possible outcomes of an experiment is known as the sample space of the experiment and is denoted by S.**

&#10230; Espaço amostral - O conjunto de todos os resultados possíveis é chamado de espaço amostral do experimento e é denotado por S.

<br>

**4. Event ― Any subset E of the sample space is known as an event. That is, an event is a set consisting of possible outcomes of the experiment. If the outcome of the experiment is contained in E, then we say that E has occurred.**

&#10230; Evento - Qualquer subconjunto E do espaço amostral é chamado de evento. Isso é, um evento é um conjunto de possíveis resultados do experimento. Se o resultado do experimento está contido em E, então é dito que o evento ocorreu.

<br>

**5. Axioms of probability For each event E, we denote P(E) as the probability of event E occuring.**

&#10230; Axiomas de probabilidade Para cada evento E, denotamos P(E) a probabilidade do evento E ocorrer. 

<br>

**6. Axiom 1 ― Every probability is between 0 and 1 included, i.e:**

&#10230; Axioma 1 - Toda probabilidade está entre 0 e 1 incluído, i.e:

<br>

**7. Axiom 2 ― The probability that at least one of the elementary events in the entire sample space will occur is 1, i.e:**

&#10230; Axioma 2 - A probabilidade de ao menos um dos eventos elementares do espaço amostral inteiro ocorrer é 1, i.e:

<br>

**8. Axiom 3 ― For any sequence of mutually exclusive events E1,...,En, we have:**

&#10230; Axioma 3 - Para qualquer sequência de eventos mutuamente exclusivos E1,...En, temos:

<br>

**9. Permutation ― A permutation is an arrangement of r objects from a pool of n objects, in a given order. The number of such arrangements is given by P(n,r), defined as:**

&#10230; Permutação - A permutação é um arranjo de r objetos de um conjunto de n objetos, em uma determinada ordem. O número desses arranjos é dado por P(n,r), definido como:

<br>

**10. Combination ― A combination is an arrangement of r objects from a pool of n objects, where the order does not matter. The number of such arrangements is given by C(n,r), defined as:**

&#10230; Combinação - A combinação de um arranjo de r objetos de um conjunto de n objetos, onde a ordem não importa. O número desses arranjos é dado por C(n,r), definido como:

<br>

**11. Remark: we note that for 0⩽r⩽n, we have P(n,r)⩾C(n,r)**

&#10230; Observação: dado que  0⩽r⩽n, então temos que P(n,r)⩾C(n,r)

<br>

**12. Conditional Probability**

&#10230; Probabilidade Condicional

<br>

**13. Bayes' rule ― For events A and B such that P(B)>0, we have:**

&#10230; Regra de Bayes - Para eventos A e B tal que P(B)>0, temos que:

<br>

**14. Remark: we have P(A∩B)=P(A)P(B|A)=P(A|B)P(B)**

&#10230; Observação: temos que P(A∩B)=P(A)P(B|A)=P(A|B)P(B)

<br>

**15. Partition ― Let {Ai,i∈[[1,n]]} be such that for all i, Ai≠∅. We say that {Ai} is a partition if we have:**

&#10230; Partição - Dado que {Ai,i∈[[1,n]]} seja tal que para todo i, Ai≠∅. Dizemos que {Ai} é uma partição se temos: 

<br>

**16. Remark: for any event B in the sample space, we have P(B)=n∑i=1P(B|Ai)P(Ai).**

&#10230; Observação: para qualquer evento B no espaço amostral temos que P(B)=n∑i=1P(B|Ai)P(Ai).

<br>

**17. Extended form of Bayes' rule ― Let {Ai,i∈[[1,n]]} be a partition of the sample space. We have:**

&#10230; Extensão da regra de Bayes -  Seja {Ai,i∈[[1,n]]} uma partição do espaço amostral. Temos que:

<br>

**18. Independence ― Two events A and B are independent if and only if we have:**

&#10230; Independência - Dois eventos A e B são independentes se e apenas se tivermos:

<br>

**19. Random Variables**

&#10230; Variáveis Aleatórias

<br>

**20. Definitions**

&#10230; Definições

<br>

**21. Random variable ― A random variable, often noted X, is a function that maps every element in a sample space to a real line.**

&#10230; Variável aleatória - Uma variável aleatória, normalmente denominada X, é uma função que mapeia todo elemento em um espaço amostral para uma linha verdadeira.

<br>

**22. Cumulative distribution function (CDF) ― The cumulative distribution function F, which is monotonically non-decreasing and is such that limx→−∞F(x)=0 and limx→+∞F(x)=1, is defined as:**

&#10230; Função de distribuição cumulativa (CDF) - A função de distribuição cumulativa F, que é monotonicamente não decrescente e é tal que limx→−∞F(x)=0 e limx→+∞F(x)=1, é definida como:

<br>

**23. Remark: we have P(a<X⩽B)=F(b)−F(a).**

&#10230; Lembrete: temos que P(a<X⩽B)=F(b)−F(a).

<br>

**24. Probability density function (PDF) ― The probability density function f is the probability that X takes on values between two adjacent realizations of the random variable.**

&#10230; Função densidade de probabilidade (PDF) - A função densidade de probabilidade f é a probabilidade de que X assuma valores entre duas realizações adjacentes da variável aleatória.

<br>

**25. Relationships involving the PDF and CDF ― Here are the important properties to know in the discrete (D) and the continuous (C) cases.**

&#10230; Relações envolvendo a PDF e a CDF - Aqui estão as propriedades mais importantes que se deve conhecer dos casos discretos (D) e contínuos (C).

<br>

**26. [Case, CDF F, PDF f, Properties of PDF]**

&#10230; [Caso, CDF, F, PDF f, Propriedades da PDF]

<br>

**27. Expectation and Moments of the Distribution ― Here are the expressions of the expected value E[X], generalized expected value E[g(X)], kth moment E[Xk] and characteristic function ψ(ω) for the discrete and continuous cases:**

&#10230; Expectativas e Momentos da Distribuição - Aqui estão as expressões do valor esperado E[X], do valor esperado generalizado E[g(X)], do k-ésimo momento E[Xk] e função característica ψ(ω) para os casos discretos e contínuos:

<br>

**28. Variance ― The variance of a random variable, often noted Var(X) or σ2, is a measure of the spread of its distribution function. It is determined as follows:**

&#10230; Variância - A variância de uma variável aleatória, normalmente denominada Var(X) ou σ2, é a medida do espalhamento da sua função de distribuição. Ela é determinada por:

<br>

**29. Standard deviation ― The standard deviation of a random variable, often noted σ, is a measure of the spread of its distribution function which is compatible with the units of the actual random variable. It is determined as follows:**

&#10230; Desvio padrão - O desvio padrão de uma variável aleatória, normalmente denominado σ, é a medida do espalhamento da sua função de distribuição que é compatível com a unidade da variável aleatória. Ele é determinado por:

<br>

**30. Transformation of random variables ― Let the variables X and Y be linked by some function. By noting fX and fY the distribution function of X and Y respectively, we have:**

&#10230; Transformação das variáveis aleatórias - Sejam as variáveis X e Y ligadas por alguma função. Ao denotador fX e fY para as funções de distribuição de X e de Y respectivamente, temos que:

<br>

**31. Leibniz integral rule ― Let g be a function of x and potentially c, and a,b boundaries that may depend on c. We have:**

&#10230; Regra integral de Leibniz - Seja g uma função de x e possivelmente de c, e a,b fronteiras que podem depender de c. Temos que:

<br>

**32. Probability Distributions**

&#10230; Distribuições de Probabilidade

<br>

**33. Chebyshev's inequality ― Let X be a random variable with expected value μ. For k,σ>0, we have the following inequality:**

&#10230; Desigualdade de Chebyshev - Seja X uma variável aleatória com valor esperado μ. Para k,σ>0, temos a seguinte desigualdade: 

<br>

**34. Main distributions ― Here are the main distributions to have in mind:**

&#10230; Distribuições principais - Aqui estão as principais distribuições que não devem ser esquecidas:

<br>

**35. [Type, Distribution]**

&#10230; [Tipo, Distribuição]

<br>

**36. Jointly Distributed Random Variables**

&#10230; Variáveis Aleatórias Distribuídas Conjuntamente

<br>

**37. Marginal density and cumulative distribution ― From the joint density probability function fXY , we have**

&#10230; Densidade marginal e distribuição cumulativa - A partir da função de probabilidade de densidade conjunta fXY, temos que:

<br>

**38. [Case, Marginal density, Cumulative function]**

&#10230; [Caso, Densidade marginal, Função cumulativa]

<br>

**39. Conditional density ― The conditional density of X with respect to Y, often noted fX|Y, is defined as follows:**

&#10230; Densidade condicional - A densidade condicional de X com respeito a Y, normalmente denotada como fX|Y, é definida como:

<br>

**40. Independence ― Two random variables X and Y are said to be independent if we have:**

&#10230; Independência - Duas variáveis aleatórias X e Y são ditas independentes se:

<br>

**41. Covariance ― We define the covariance of two random variables X and Y, that we note σ2XY or more commonly Cov(X,Y), as follows:**

&#10230; Coveriância - Definimos covariância de duas variáveis aleatórias X e Y, que chamamos de σ2XY ou mais comumente de Cov(X,Y), como:

<br>

**42. Correlation ― By noting σX,σY the standard deviations of X and Y, we define the correlation between the random variables X and Y, noted ρXY, as follows:**

&#10230; Correlação - Dado que σX,σY são os desvios padrão de X e Y, definimos a correlação entre as variáveis aleatórias X e Y, denominada ρXY, como:

<br>

**43. Remark 1: we note that for any random variables X,Y, we have ρXY∈[−1,1].**

&#10230; Observação 1: é definido que para qualquer variáveis aleatórias X,Y temos que ρXY∈[−1,1].

<br>

**44. Remark 2: If X and Y are independent, then ρXY=0.**

&#10230; Observação 2: Se X e Y são independentes, então ρXY=0.

<br>

**45. Parameter estimation**

&#10230; Estimativa de parâmetro

<br>

**46. Definitions**

&#10230; Definições

<br>

**47. Random sample ― A random sample is a collection of n random variables X1,...,Xn that are independent and identically distributed with X.**

&#10230; Amostra aleatória - Uma amostra aleatória é uma coleção de n variáveis aleatórias X1,...,Xn que são independentes e igualmente distribuidas com X.

<br>

**48. Estimator ― An estimator is a function of the data that is used to infer the value of an unknown parameter in a statistical model.**

&#10230; Estimador - Um estimador é uma função dos dados que é usada para inferir o valor de um parâmetro desconhecido em um modelo estatístico.

<br>

**49. Bias ― The bias of an estimator ^θ is defined as being the difference between the expected value of the distribution of ^θ and the true value, i.e.:**

&#10230; Viés (Bias) - O viés de um estimador ^θ é definido como a diferença entre o valor esperado da distribuição de ^θ e o seu real valor, i.e.:

<br>

**50. Remark: an estimator is said to be unbiased when we have E[^θ]=θ.**

&#10230; Observação: um estimador é chamado de imparcial (unbiased) quando E[^θ]=θ. 

<br>

**51. Estimating the mean**

&#10230; Estimando a média

<br>

**52. Sample mean ― The sample mean of a random sample is used to estimate the true mean μ of a distribution, is often noted ¯¯¯¯¯X and is defined as follows:**

&#10230; Média da amostra - A média da amostra de uma amostra aleatória é usada para estimar a verdadeira média μ de uma distribuição, e é denominada ¯¯¯¯¯X e é definida como:

<br>

**53. Remark: the sample mean is unbiased, i.e E[¯¯¯¯¯X]=μ.**

&#10230; Observação: a média da amostra é imparcial, i.e E[¯¯¯¯¯X]=μ.

<br>

**54. Central Limit Theorem ― Let us have a random sample X1,...,Xn following a given distribution with mean μ and variance σ2, then we have:**

&#10230; Teorema do Limite Central - Dado que temos uma amostra aleatória X1,...,Xn seguindo uma determinada distribuição com a média μ e a variância σ2, temos que:

<br>

**55. Estimating the variance**

&#10230; Estimando a variância

<br>

**56. Sample variance ― The sample variance of a random sample is used to estimate the true variance σ2 of a distribution, is often noted s2 or ^σ2 and is defined as follows:**

&#10230; Amostra da variância - A amostra da variância de uma amostra aleatória é usada para estimar a verdadeira variância σ2 da distribuição, e é normalmente denominada s2 ou ^σ2 e definida por:

<br>

**57. Remark: the sample variance is unbiased, i.e E[s2]=σ2.**

&#10230; Observação: a variância da amostra é imparcial, i.e E[s2]=σ2.

<br>

**58. Chi-Squared relation with sample variance ― Let s2 be the sample variance of a random sample. We have:**

&#10230; Relação qui-quadrado com a variância da amostra - Seja s2 a variância da amostra de uma amostra aleatória. Nós temos:

<br>

**59. [Introduction, Sample space, Event, Permutation]**

&#10230; [Introdução, Espaço amostral, Evento, Permutação]

<br>

**60. [Conditional probability, Bayes' rule, Independence]**

&#10230; [Probabilidade condicional, Regra de Bayes, Independência]

<br>

**61. [Random variables, Definitions, Expectation, Variance]**

&#10230; [Variáveis aleatórias, Definições, Expectativa, Variância]

<br>

**62. [Probability distributions, Chebyshev's inequality, Main distributions]**

&#10230; [Distribuições de probabilidade, Desigualdade de Chebyshev, Distribuições principais]

<br>

**63. [Jointly distributed random variables, Density, Covariance, Correlation]**

&#10230; [Variáveis aleatórias distribuidas em conjunto, Densidade, Covariância, Correlação]

<br>

**64. [Parameter estimation, Mean, Variance]**

&#10230; [Estimativa de parâmetro, Média, Variância]
